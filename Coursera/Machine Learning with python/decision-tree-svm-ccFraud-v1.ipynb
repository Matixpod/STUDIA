{"cells":[{"cell_type":"markdown","id":"06bd7e52-63c1-42f1-9b5e-0bddf07ed873","metadata":{},"outputs":[],"source":["<center>\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\">\n","</center>\n"]},{"cell_type":"markdown","id":"e2267ffc-d427-4a34-b78d-6fcaf54627b4","metadata":{},"outputs":[],"source":["# **Credit Card Fraud Detection with Decision Trees and SVM**\n"]},{"cell_type":"markdown","id":"42167cb0-49ce-4d37-af40-2abe99d090be","metadata":{},"outputs":[],"source":["Estimated time needed: **30** minutes\n"]},{"cell_type":"markdown","id":"897f9230-7324-4b69-8075-e3ebd7b5010f","metadata":{},"outputs":[],"source":["In this lab you will consolidate your machine learning (ML) modeling skills by using two popular classification models to identify fraudulent credit card transactions. These models are: Decision Tree and Support Vector Machine. You will use a real dataset of credit card transactions to train each of these models. You will then use the trained model to assess if a credit card transaction is fraudulent or not.\n"]},{"cell_type":"markdown","id":"c5379ca6-6863-4750-859c-df41abd58ce3","metadata":{},"outputs":[],"source":["## Objectives\n"]},{"cell_type":"markdown","id":"114f3d30-f844-4916-bef8-d8e5f32d141a","metadata":{},"outputs":[],"source":["After completing this lab you will be able to:\n"]},{"cell_type":"markdown","id":"45c8fc32-05a3-4eab-bcc4-101ce2639b13","metadata":{},"outputs":[],"source":["* Perform basic data preprocessing in Python\n","* Model a classification task using the Scikit-Learn Python APIs\n","* Train Suppport Vector Machine and Decision Tree models using Scikit-Learn\n","* Run inference and assess the quality of the trained models\n"]},{"cell_type":"markdown","id":"df14a33b-cad2-4e78-a0da-013ea2f45d4a","metadata":{},"outputs":[],"source":["<div id=\"Introduction\">\n","    <h2>Introduction</h2>\n","    <br>Imagine that you work for a financial institution and part of your job is to build a model that predicts if a credit card transaction is fraudulent or not. You can model the problem as a binary classification problem. A transaction belongs to the positive class (1) if it is a fraud, otherwise it belongs to the negative class (0).\n","    <br>\n","    <br>You have access to transactions that occured over a certain period of time. The majority of the transactions are normally legitimate and only a small fraction are non-legitimate. Thus, typically you have access to a dataset that is highly unbalanced. This is also the case of the current dataset: only 492 transactions out of 284,807 are fraudulent (the positive class - the frauds - accounts for 0.172% of all transactions).\n","    <br>\n","    <br>This is a Kaggle dataset. You can find this \"Credit Card Fraud Detection\" dataset from the following link: <a href=\"https://www.kaggle.com/mlg-ulb/creditcardfraud\">Credit Card Fraud Detection</a>.\n","<br>\n","    <br>To train the model, you can use part of the input dataset, while the remaining data can be utilized to assess the quality of the trained model. First, let's import the necessary libraries and download the dataset.\n","    <br>\n","</div>\n"]},{"cell_type":"markdown","id":"12614f2f-c54f-4dc7-81b1-1c83fb0deb7c","metadata":{},"outputs":[],"source":["<div id=\"import_libraries\">\n","    <h2>Import Libraries</h2>\n","</div>\n"]},{"cell_type":"markdown","id":"1901739d-a1d8-4566-992b-d5987d079e1e","metadata":{},"outputs":[],"source":["First, make sure that the required libraries are available. Run the cell below to ensure that.\n"]},{"cell_type":"code","id":"6bee2c01-c86f-47c2-89d8-8d2acbd13a1c","metadata":{},"outputs":[],"source":["!pip install pandas==2.2.3\n!pip install scikit-learn==1.6.0\n!pip install matplotlib==3.9.3"]},{"cell_type":"markdown","id":"3178cf8f-3c51-4828-a346-92c399cf585d","metadata":{},"outputs":[],"source":["To import the libraries that will be used in this lab, execute the cells below. \n"]},{"cell_type":"code","id":"33d5a40e-507e-458c-901f-67f95a8e5a1c","metadata":{},"outputs":[],"source":["# Import the libraries we need to use in this lab\nfrom __future__ import print_function\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import normalize, StandardScaler\nfrom sklearn.utils.class_weight import compute_sample_weight\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.svm import LinearSVC\n\nimport warnings\nwarnings.filterwarnings('ignore')"]},{"cell_type":"markdown","id":"e579c7f1-ac8b-4357-aa87-1bdba2162cb7","metadata":{},"outputs":[],"source":["## Load the dataset\n","\n","Execute the cell below to load the dataset to the variable `raw_data`. The code will fetch the data set for the URL and load the same to the variable. A snapshot of the dataset will be generated as an output.\n"]},{"cell_type":"code","id":"1328a7f1-2e0d-48c6-93ad-b1b8d8e1fbde","metadata":{},"outputs":[],"source":["# download the dataset\nurl= \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%203/data/creditcard.csv\"\n\n# read the input data\nraw_data=pd.read_csv(url)\nraw_data"]},{"cell_type":"markdown","id":"4766144e-43c3-4a1c-a6f1-4a1a29cf26af","metadata":{},"outputs":[],"source":["<div id=\"dataset_analysis\">\n","    <h2>Dataset Analysis</h2>\n","</div>\n"]},{"cell_type":"markdown","id":"da5fc266-b14c-4456-aa67-2d4f3cbea5fa","metadata":{},"outputs":[],"source":["Each row in the dataset represents a credit card transaction. As shown above, each row has 31 variables. One variable (the last variable in the table above) is called Class and represents the target variable. Your objective will be to train a model that uses the other variables to predict the value of the Class variable. Let's first retrieve basic statistics about the target variable.\n","\n","Note: For confidentiality reasons, the original names of most features are anonymized V1, V2 .. V28. The values of these features are the result of a PCA transformation and are numerical. The feature 'Class' is the target variable and it takes two values: 1 in case of fraud and 0 otherwise. For more information about the dataset please visit this webpage: https://www.kaggle.com/mlg-ulb/creditcardfraud.\n"]},{"cell_type":"code","id":"d14fcb16-cb37-4311-9d72-70537f972a25","metadata":{},"outputs":[],"source":["# get the set of distinct classes\nlabels = raw_data.Class.unique()\n\n# get the count of each class\nsizes = raw_data.Class.value_counts().values\n\n# plot the class value counts\nfig, ax = plt.subplots()\nax.pie(sizes, labels=labels, autopct='%1.3f%%')\nax.set_title('Target Variable Value Counts')\nplt.show()"]},{"cell_type":"markdown","id":"cc283c25-92d3-4350-a0f0-57c5dc050c19","metadata":{},"outputs":[],"source":["As shown above, the Class variable has two values: 0 (the credit card transaction is legitimate) and 1 (the credit card transaction is fraudulent). Thus, you need to model a binary classification problem. Moreover, the dataset is highly unbalanced, the target variable classes are not represented equally. This case requires special attention when training or when evaluating the quality of a model. One way of handing this case at train time is to bias the model to pay more attention to the samples in the minority class. The models under the current study will be configured to take into account the class weights of the samples at train/fit time.\n"]},{"cell_type":"markdown","id":"c5fb9e0c-07a2-4799-ae4b-ce1ea04fb0ed","metadata":{},"outputs":[],"source":["It is also prudent to understand which features affect the model in what way. We can visualize the effect of the different features on the model using the code below.\n"]},{"cell_type":"code","id":"76547290-b02d-4882-aa26-51dd02831633","metadata":{},"outputs":[],"source":["correlation_values = raw_data.corr()['Class'].drop('Class')\ncorrelation_values.plot(kind='barh', figsize=(10, 6))"]},{"cell_type":"markdown","id":"8af0b5de-53e5-4177-86bf-371eff6388fc","metadata":{},"outputs":[],"source":["This clearly shows that some features affect the output Class more than the others. For efficient modeling, we may use only the most correlated features.\n"]},{"cell_type":"markdown","id":"32128e91-7020-490d-9dd4-391d4f30d1fb","metadata":{},"outputs":[],"source":["<div id=\"dataset_preprocessing\">\n","    <h2>Dataset Preprocessing</h2>\n","</div>\n"]},{"cell_type":"markdown","id":"3330a1b9-9de3-4c0f-9507-be4a0a9adc15","metadata":{},"outputs":[],"source":["You will now prepare the data for training. You will apply standard scaling to the input features and normalize them using $L_1$ norm for the training models to converge quickly. As seen in the data snapshot, there is a parameter called `Time` which we will not be considering for modeling. Hence, features 2 to 30 will be used as input features and feature 31, i.e. Class will be used as the target variable.\n"]},{"cell_type":"code","id":"e28ed743-6e71-4d33-81ad-8b3c29c41bb2","metadata":{},"outputs":[],"source":["# standardize features by removing the mean and scaling to unit variance\nraw_data.iloc[:, 1:30] = StandardScaler().fit_transform(raw_data.iloc[:, 1:30])\ndata_matrix = raw_data.values\n\n# X: feature matrix (for this analysis, we exclude the Time variable from the dataset)\nX = data_matrix[:, 1:30]\n\n# y: labels vector\ny = data_matrix[:, 30]\n\n# data normalization\nX = normalize(X, norm=\"l1\")"]},{"cell_type":"markdown","id":"5f3519f9-37f0-4be3-9fe7-37d8ff2dee38","metadata":{},"outputs":[],"source":["<div id=\"dataset_split\">\n","    <h2>Dataset Train/Test Split</h2>\n","</div>\n"]},{"cell_type":"markdown","id":"1d7975f9-baea-4452-8ab6-a1c7718b4e96","metadata":{},"outputs":[],"source":["Now that the dataset is ready for building the classification models, you need to first divide the pre-processed dataset into a subset to be used for training the model (the train set) and a subset to be used for evaluating the quality of the model (the test set).\n"]},{"cell_type":"code","id":"a55e708b-58bc-4cb1-9ad9-95f92d447067","metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"]},{"cell_type":"markdown","id":"42aae8a7-d26f-4bf1-bcef-f7f760beed9f","metadata":{},"outputs":[],"source":["<div id=\"dt_sklearn\">\n","    <h2>Build a Decision Tree Classifier model with Scikit-Learn</h2>\n","</div>\n"]},{"cell_type":"markdown","id":"48f68eae-c66d-49c1-bf32-a44a670d74e0","metadata":{},"outputs":[],"source":["Compute the sample weights to be used as input to the train routine so that it takes into account the class imbalance present in this dataset.\n"]},{"cell_type":"code","id":"8e84d0d7-6d40-45f2-9762-0fa9a02e95b4","metadata":{},"outputs":[],"source":["w_train = compute_sample_weight('balanced', y_train)"]},{"cell_type":"markdown","id":"8a1c0183-9b2a-4984-adba-08d94ea1809a","metadata":{},"outputs":[],"source":["Using these sample weights, we may train the Decision Tree classifier. We also make note of the time it takes for training this model to compare it against SVM, later in the lab.\n"]},{"cell_type":"code","id":"0566d151-1161-4d97-9d1f-00c49094a714","metadata":{},"outputs":[],"source":["# for reproducible output across multiple function calls, set random_state to a given integer value\ndt = DecisionTreeClassifier(max_depth=4, random_state=35)\n\ndt.fit(X_train, y_train, sample_weight=w_train)"]},{"cell_type":"markdown","id":"dd60a4af-a664-420d-b9bf-a702f5405010","metadata":{},"outputs":[],"source":["<div id=\"svm_sklearn\">\n","    <h2>Build a Support Vector Machine model with Scikit-Learn</h2>\n","</div>\n"]},{"cell_type":"markdown","id":"ca96da79-5706-4e42-8732-af80aae0ba06","metadata":{},"outputs":[],"source":["Unlike Decision Trees, we do not need to initiate a separate sample_weight for SVMs. We can simply pass a parameter in the scikit-learn function.\n"]},{"cell_type":"code","id":"937257b9-0307-4352-97a9-31f11203cc5a","metadata":{},"outputs":[],"source":["# for reproducible output across multiple function calls, set random_state to a given integer value\nsvm = LinearSVC(class_weight='balanced', random_state=31, loss=\"hinge\", fit_intercept=False)\n\nsvm.fit(X_train, y_train)"]},{"cell_type":"markdown","id":"f7f09434-908f-428a-b631-6e3957fcda7f","metadata":{},"outputs":[],"source":["<div id=\"dt_sklearn_snapml\">\n","    <h2>Evaluate the Decision Tree Classifier Models</h2>\n","</div>\n"]},{"cell_type":"markdown","id":"dff43ba0-24bb-4c2e-aa29-daa37793c322","metadata":{},"outputs":[],"source":["Run the following cell to compute the probabilities of the test samples belonging to the class of fraudulent transactions. \n"]},{"cell_type":"code","id":"3f941e4e-d7ed-45ff-9036-4f843e7de5f2","metadata":{},"outputs":[],"source":["y_pred_dt = dt.predict_proba(X_test)[:,1]"]},{"cell_type":"markdown","id":"35fd7d2f-b68a-4f7c-956d-20e850ea2b92","metadata":{},"outputs":[],"source":["Using these probabilities, we can evaluate the Area Under the Receiver Operating Characteristic Curve (ROC-AUC) score as a metric of model performance. \n","The AUC-ROC score evaluates your model's ability to distinguish positive and negative classes considering all possible probability thresholds. The higher its value, the better the model is considered for separating the two classes of values.\n"]},{"cell_type":"code","id":"53ab939a-0a10-4cfc-8e2d-dce7953c900a","metadata":{},"outputs":[],"source":["roc_auc_dt = roc_auc_score(y_test, y_pred_dt)\nprint('Decision Tree ROC-AUC score : {0:.3f}'.format(roc_auc_dt))"]},{"cell_type":"markdown","id":"5a4326b4-9f8c-45f9-a77c-7bb0554b8c06","metadata":{},"outputs":[],"source":["<div id=\"svm_sklearn_snap\">\n","    <h2>Evaluate the Support Vector Machine Models</h2>\n","</div>\n"]},{"cell_type":"markdown","id":"5fd71fac-5b94-41bc-9875-15f68f4cd74b","metadata":{},"outputs":[],"source":["Run the following cell to compute the probabilities of the test samples belonging to the class of fraudulent transactions. \n"]},{"cell_type":"code","id":"341e41b5-af11-4970-a12a-afa4b6e251d2","metadata":{},"outputs":[],"source":["y_pred_svm = svm.decision_function(X_test)"]},{"cell_type":"markdown","id":"66e16a5f-fa1b-407a-ac1e-6706778010b1","metadata":{},"outputs":[],"source":["You may now evaluate the accuracy of SVM on the test set in terms of the ROC-AUC score.\n"]},{"cell_type":"code","id":"0a6e3486-98f1-4ebc-90d1-d4e4e4324374","metadata":{},"outputs":[],"source":["roc_auc_svm = roc_auc_score(y_test, y_pred_svm)\nprint(\"SVM ROC-AUC score: {0:.3f}\".format(roc_auc_svm))"]},{"cell_type":"markdown","id":"7caadc26-3c41-4329-8a32-98ce9f10a569","metadata":{},"outputs":[],"source":["## Practice Exercises\n","Based on what you have learnt in this lab, attempt the following questions.\n"]},{"cell_type":"markdown","id":"31f8bcd9-d7ef-40a3-9809-579372196220","metadata":{},"outputs":[],"source":["Q1. Currently, we have used all 30 features of the dataset for training the models. Use the `corr()` function to find the top 6 features of the dataset to train the models on. \n"]},{"cell_type":"code","id":"7790e956-7edf-4881-bded-3a91d8ee6d68","metadata":{},"outputs":[],"source":["# your code goes here\ncorrelation_values = abs(....corr()['Class']).drop('Class')\ncorrelation_values = correlation_values.sort_values(ascending=False)[...]\ncorrelation_values"]},{"cell_type":"markdown","id":"4814c115-a9d3-4c73-9b98-6e1f1931be1d","metadata":{},"outputs":[],"source":["<details><summary>Click here for solution</summary>\n","\n","```python\n","correlation_values = abs(raw_data.corr()['Class']).drop('Class')\n","correlation_values = correlation_values.sort_values(ascending=False)[:6]\n","correlation_values\n","```\n","\n","<br>\n","The answer should be 'V3','V10','V12','V14','V16' and 'V17'.\n","</details>\n"]},{"cell_type":"markdown","id":"1ff0d7da-769c-400e-82fa-4fc432eae311","metadata":{},"outputs":[],"source":["Q2. Using only these 6 features, modify the input variable for training.\n"]},{"cell_type":"code","id":"e4fd75c4-0ef4-49d8-8df0-f1b997be1a51","metadata":{},"outputs":[],"source":["# your code goes here"]},{"cell_type":"markdown","id":"9054bf90-adaa-4dfa-acce-fe9f8421af9e","metadata":{},"outputs":[],"source":["<details><summary>Click here for solution</summary>\n","Replace the statement defining the variable `X` with the following and run the cell again.\n","<br>\n","\n","```python\n","X = data_matrix[:,[3,10,12,14,16,17]]\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","id":"8fd8d7da-3757-419d-9243-908fc8d517b9","metadata":{},"outputs":[],"source":["Q3. Execute the Decision Tree model for this modified input variable. How does the value of ROC-AUC metric change?\n"]},{"cell_type":"markdown","id":"2f6b3738-de70-4bcb-a659-56be84ca8ee3","metadata":{},"outputs":[],"source":["<details><summary>Click here for solution</summary>\n","You should observe an increase in the ROC-AUC value with this change for the Decision Tree model.\n","</details>\n"]},{"cell_type":"markdown","id":"e5459c09-d182-436d-8167-ba7f807aef49","metadata":{},"outputs":[],"source":["Q4. Execute the SVM model for this modified input variable. How does the value of ROC-AUC metric change?\n"]},{"cell_type":"markdown","id":"c89c2900-f99f-49a1-aecb-1c26272e1a16","metadata":{},"outputs":[],"source":["<details><summary>Click here for solution</summary>\n","You should observe a decrease in the ROC-AUC value with this change for the SVM model.\n","</details>\n"]},{"cell_type":"markdown","id":"d0cc143d-a4a3-4ed0-84be-2aa206aee991","metadata":{},"outputs":[],"source":["Q5. What are the inferences you can draw about Decision Trees and SVMs with what you have learnt in this lab?\n"]},{"cell_type":"markdown","id":"c89fc432-6d0a-4262-9490-244561c3a7a4","metadata":{},"outputs":[],"source":["<details><summary>Click here for solution</summary>\n","\n","- With a larger set of features, SVM performed relatively better in comparison to the Decision Trees.\n","- Decision Trees benefited from feature selection and performed better.\n","- SVMs may require higher feature dimensionality to create an efficient decision hyperplane.\n","</details>\n"]},{"cell_type":"markdown","id":"d982656f-f4ef-48bf-ae0a-7b82034c7a23","metadata":{},"outputs":[],"source":["### Congratulations! You're ready to move on to your next lesson!\n"," \n","## Author\n"," \n","<a href=\"https://www.linkedin.com/in/abhishek-gagneja-23051987/\" target=\"_blank\">Abishek Gagneja</a>\n"," \n"," \n"," ### Other Contributors\n"," \n","<a href=\"https://www.linkedin.com/in/jpgrossman/\" target=\"_blank\">Jeff Grossman</a>\n","\n","<!--\n","## Changelog\n"," \n","| Date | Version | Changed by | Change Description |\n","\r\n","|:------------|:------|:------------------|:---------------------------------------|\n","\r\n","| 2024--1405 | 1.|0  Abhishek Gagnean    | Update content and practice exercis|es>\n"," \n"]},{"cell_type":"markdown","id":"c72a3185-27af-4752-8c79-2c48e55ab02c","metadata":{},"outputs":[],"source":["## <h3 align=\"center\"> © IBM Corporation. All rights reserved. <h3/>\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"prev_pub_hash":"e4a378c2f5b6144d47f9f9e22188613f8521d0594defd52e93c38f8c51ba2243"},"nbformat":4,"nbformat_minor":4}